----------------------------------------------------------------------------------
| eval/episode_length                | 321      |
| eval/episode_length_std            | 38.3     |
| eval/normalized_episode_reward     | 8.45     |
| eval/normalized_episode_reward_std | 5.16     |
| loss/actor                         | 4.93     |
| loss/q1                            | 0.0441   |
| loss/q2                            | 0.0423   |
| loss/v                             | 0.00775  |
| timestep                           | 1000     |
----------------------------------------------------------------------------------
best_reward_mean: 8.45, best_reward_std: 5.16
----------------------------------------------------------------------------------
| eval/episode_length                | 252      |
| eval/episode_length_std            | 21.9     |
| eval/normalized_episode_reward     | 13.8     |
| eval/normalized_episode_reward_std | 2.06     |
| loss/actor                         | 3.22     |
| loss/q1                            | 0.0551   |
| loss/q2                            | 0.0539   |
| loss/v                             | 0.0059   |
| timestep                           | 2000     |
----------------------------------------------------------------------------------
best_reward_mean: 13.82, best_reward_std: 2.06
----------------------------------------------------------------------------------
| eval/episode_length                | 640      |
| eval/episode_length_std            | 105      |
| eval/normalized_episode_reward     | 53.6     |
| eval/normalized_episode_reward_std | 11.3     |
| loss/actor                         | 1.95     |
| loss/q1                            | 0.115    |
| loss/q2                            | 0.113    |
| loss/v                             | 0.00938  |
| timestep                           | 3000     |
----------------------------------------------------------------------------------
best_reward_mean: 53.56, best_reward_std: 11.28
----------------------------------------------------------------------------------
| eval/episode_length                | 516      |
| eval/episode_length_std            | 100      |
| eval/normalized_episode_reward     | 34.9     |
| eval/normalized_episode_reward_std | 10.7     |
| loss/actor                         | 0.977    |
| loss/q1                            | 0.163    |
| loss/q2                            | 0.161    |
| loss/v                             | 0.0123   |
| timestep                           | 4000     |
----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| eval/episode_length                | 171      |
| eval/episode_length_std            | 255      |
| eval/normalized_episode_reward     | 13.5     |
| eval/normalized_episode_reward_std | 21.4     |
| loss/actor                         | 0.507    |
| loss/q1                            | 0.227    |
| loss/q2                            | 0.224    |
| loss/v                             | 0.0167   |
| timestep                           | 5000     |
----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| eval/episode_length                | 753      |
| eval/episode_length_std            | 191      |
| eval/normalized_episode_reward     | 46.1     |
| eval/normalized_episode_reward_std | 20.1     |
| loss/actor                         | 0.426    |
| loss/q1                            | 0.293    |
| loss/q2                            | 0.289    |
| loss/v                             | 0.0223   |
| timestep                           | 6000     |
----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| eval/episode_length                | 708      |
| eval/episode_length_std            | 257      |
| eval/normalized_episode_reward     | 48.6     |
| eval/normalized_episode_reward_std | 25.7     |
| loss/actor                         | 0.464    |
| loss/q1                            | 0.338    |
| loss/q2                            | 0.334    |
| loss/v                             | 0.0284   |
| timestep                           | 7000     |
----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| eval/episode_length                | 626      |
| eval/episode_length_std            | 261      |
| eval/normalized_episode_reward     | 51.4     |
| eval/normalized_episode_reward_std | 24.6     |
| loss/actor                         | 0.631    |
| loss/q1                            | 0.375    |
| loss/q2                            | 0.368    |
| loss/v                             | 0.0356   |
| timestep                           | 8000     |
----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| eval/episode_length                | 443      |
| eval/episode_length_std            | 45       |
| eval/normalized_episode_reward     | 33.5     |
| eval/normalized_episode_reward_std | 4.45     |
| loss/actor                         | 0.737    |
| loss/q1                            | 0.446    |
| loss/q2                            | 0.438    |
| loss/v                             | 0.042    |
| timestep                           | 9000     |
----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| eval/episode_length                | 7        |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | -0.0922  |
| eval/normalized_episode_reward_std | -0.0342  |
| loss/actor                         | 0.689    |
| loss/q1                            | 0.453    |
| loss/q2                            | 0.447    |
| loss/v                             | 0.0502   |
| timestep                           | 10000    |
----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| eval/episode_length                | 576      |
| eval/episode_length_std            | 69.2     |
| eval/normalized_episode_reward     | 44.6     |
| eval/normalized_episode_reward_std | 7.81     |
| loss/actor                         | 0.783    |
| loss/q1                            | 0.492    |
| loss/q2                            | 0.482    |
| loss/v                             | 0.0541   |
| timestep                           | 11000    |
----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| eval/episode_length                | 209      |
| eval/episode_length_std            | 102      |
| eval/normalized_episode_reward     | 4.68     |
| eval/normalized_episode_reward_std | 10.1     |
| loss/actor                         | 0.706    |
| loss/q1                            | 0.508    |
| loss/q2                            | 0.5      |
| loss/v                             | 0.0636   |
| timestep                           | 12000    |
----------------------------------------------------------------------------------
